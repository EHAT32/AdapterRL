{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2294a2a",
   "metadata": {},
   "source": [
    "### Извлечение признаков из VPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355186c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minestudio.models import VPTPolicy\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7cf650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VPTPolicy(\n",
       "  (value_head): ScaledMSEHead(\n",
       "    (linear): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (normalizer): NormalizeEwma()\n",
       "  )\n",
       "  (pi_head): DictActionHead(\n",
       "    (buttons): CategoricalActionHead(\n",
       "      (linear_layer): Linear(in_features=2048, out_features=8641, bias=True)\n",
       "    )\n",
       "    (camera): CategoricalActionHead(\n",
       "      (linear_layer): Linear(in_features=2048, out_features=121, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (net): MinecraftPolicy(\n",
       "    (img_preprocess): ImgPreprocessing()\n",
       "    (img_process): ImgObsProcess(\n",
       "      (cnn): ImpalaCNN(\n",
       "        (stacks): ModuleList(\n",
       "          (0): CnnDownStack(\n",
       "            (firstconv): FanInInitReLULayer(\n",
       "              (layer): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (n): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "            (blocks): ModuleList(\n",
       "              (0-1): 2 x CnnBasicBlock(\n",
       "                (conv0): FanInInitReLULayer(\n",
       "                  (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "                  (layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                )\n",
       "                (conv1): FanInInitReLULayer(\n",
       "                  (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "                  (layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): CnnDownStack(\n",
       "            (firstconv): FanInInitReLULayer(\n",
       "              (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "              (layer): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "            (n): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "            (blocks): ModuleList(\n",
       "              (0-1): 2 x CnnBasicBlock(\n",
       "                (conv0): FanInInitReLULayer(\n",
       "                  (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "                  (layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                )\n",
       "                (conv1): FanInInitReLULayer(\n",
       "                  (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "                  (layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): CnnDownStack(\n",
       "            (firstconv): FanInInitReLULayer(\n",
       "              (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "              (layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "            (n): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "            (blocks): ModuleList(\n",
       "              (0-1): 2 x CnnBasicBlock(\n",
       "                (conv0): FanInInitReLULayer(\n",
       "                  (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "                  (layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                )\n",
       "                (conv1): FanInInitReLULayer(\n",
       "                  (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "                  (layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (dense): FanInInitReLULayer(\n",
       "          (norm): LayerNorm((65536,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer): Linear(in_features=65536, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (linear): FanInInitReLULayer(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer): Linear(in_features=256, out_features=2048, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (recurrent_layer): ResidualRecurrentBlocks(\n",
       "      (blocks): ModuleList(\n",
       "        (0-3): 4 x ResidualRecurrentBlock(\n",
       "          (mlp0): FanInInitReLULayer(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (layer): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          )\n",
       "          (mlp1): FanInInitReLULayer(\n",
       "            (layer): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          )\n",
       "          (pre_r_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (r): MaskedAttention(\n",
       "            (orc_block): SelfAttentionLayer(\n",
       "              (q_layer): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (k_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (proj_layer): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (r_layer): Linear(in_features=2048, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lastlayer): FanInInitReLULayer(\n",
       "      (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "    )\n",
       "    (final_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VPTPolicy.from_pretrained(\"CraftJarvis/MineStudio_VPT.rl_from_early_game_2x\").to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176f4f7",
   "metadata": {},
   "source": [
    "Имплементация VPTPolicy такова, что есть несколько модулей у нашей model:\n",
    "* model.net - сам VPT для извлечения признаков, генерация скрытых представлений для pi и value голов. Важно отметить, что генерируемые латенты для pi и value одинаковые. Также модель кэширует предыдущие состояния для эффективного подсчёта в инфиренсе.\n",
    "* model.pi_head - модуль для генерации действий\n",
    "* model.value_head - модуль для генерации ценности\n",
    "\n",
    "Вот кусок кода, нас интересует метод forward\n",
    "\n",
    "```python\n",
    "class VPTPolicy(MinePolicy, PyTorchModelHubMixin):\n",
    "    def forward(self, input, state_in, **kwargs):\n",
    "        \"\"\"Forward pass of the VPTPolicy.\n",
    "\n",
    "        Takes observations and recurrent state, passes them through the underlying\n",
    "        `MinecraftPolicy` network, and then through policy and value heads.\n",
    "\n",
    "        :param input: Dictionary of input observations, expected to contain \"image\".\n",
    "                      The \"image\" tensor should have shape (B, T, H, W, C) or similar.\n",
    "        :type input: Dict[str, torch.Tensor]\n",
    "        :param state_in: Input recurrent state. If None, an initial state is generated.\n",
    "        :type state_in: Optional[List[torch.Tensor]]\n",
    "        :param kwargs: Additional keyword arguments (not directly used in this method but part of signature).\n",
    "        :returns: A tuple containing:\n",
    "            - latents (Dict[str, torch.Tensor]): Dictionary with 'pi_logits' and 'vpred'.\n",
    "            - state_out (List[torch.Tensor]): Output recurrent state.\n",
    "        :rtype: Tuple[Dict[str, torch.Tensor], List[torch.Tensor]]\n",
    "        \"\"\"\n",
    "        B, T = input[\"image\"].shape[:2]\n",
    "        first = torch.tensor([[False]], device=self.device).repeat(B, T)\n",
    "        state_in = self.initial_state(B) if state_in is None else state_in\n",
    "\n",
    "        #input: 1, 128, 128, 128, 3\n",
    "        #first: 1, 128\n",
    "        # state_in[0]: 1, 1, 1, 128\n",
    "        # state_in[1]: 1, 1, 128, 128\n",
    "        try:\n",
    "            (pi_h, v_h), state_out = self.net(input, state_in, context={\"first\": first})\n",
    "        except Exception as e:\n",
    "            import ray\n",
    "            ray.util.pdb.set_trace()\n",
    "        pi_logits = self.pi_head(pi_h)\n",
    "        vpred = self.value_head(v_h)\n",
    "        latents = {'pi_logits': pi_logits, 'vpred': vpred}\n",
    "        return latents, state_out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0299f95",
   "metadata": {},
   "source": [
    "А вот метод forward у самой model.net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c3f52",
   "metadata": {},
   "source": [
    "```python\n",
    "class MinecraftPolicy(nn.Module):\n",
    "        def forward(self, ob, state_in, context):\n",
    "        \"\"\"Forward pass of the MinecraftPolicy.\n",
    "\n",
    "        Processes image observations, passes them through recurrent layers, and produces\n",
    "        latent representations.\n",
    "\n",
    "        :param ob: Dictionary of observations, expected to contain \"image\".\n",
    "        :type ob: Dict[str, torch.Tensor]\n",
    "        :param state_in: Input recurrent state.\n",
    "        :type state_in: Any # Type depends on recurrence_type\n",
    "        :param context: Context dictionary, expected to contain \"first\" (a tensor indicating episode starts).\n",
    "        :type context: Dict[str, torch.Tensor]\n",
    "        :returns: A tuple containing:\n",
    "            - pi_latent_or_tuple (Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]):\n",
    "                If `single_output` is True, this is a single tensor for both policy and value.\n",
    "                Otherwise, it's a tuple (pi_latent, vf_latent).\n",
    "            - state_out (Any): Output recurrent state.\n",
    "        :rtype: Tuple[Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]], Any]\n",
    "        \"\"\"\n",
    "        first = context[\"first\"]\n",
    "        x = self.img_preprocess(ob[\"image\"])\n",
    "        x = self.img_process(x)\n",
    "\n",
    "        if self.diff_obs_process:\n",
    "            processed_obs = self.diff_obs_process(ob[\"diff_goal\"])\n",
    "            x = processed_obs + x\n",
    "\n",
    "        if self.pre_lstm_ln is not None:\n",
    "            x = self.pre_lstm_ln(x)\n",
    "\n",
    "        if self.recurrent_layer is not None:\n",
    "            x, state_out = self.recurrent_layer(x, first, state_in)\n",
    "        else:\n",
    "            state_out = state_in\n",
    "\n",
    "        x = F.relu(x, inplace=False)\n",
    "\n",
    "        x = self.lastlayer(x)\n",
    "        x = self.final_ln(x)\n",
    "        pi_latent = vf_latent = x\n",
    "        if self.single_output:\n",
    "            return pi_latent, state_out\n",
    "        return (pi_latent, vf_latent), state_out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e4aa5",
   "metadata": {},
   "source": [
    "pi_latent и vf_latent одинаковые, входные изображения должны быть вида (B, T, H, W, C). Попробуем вогнать пробный тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8c7d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 129, 2048])\n"
     ]
    }
   ],
   "source": [
    "B = 2\n",
    "T = 129\n",
    "input = {\"image\": torch.zeros(B, T, 128, 128, 3, device=\"cuda\")}\n",
    "first = torch.zeros((B, T), dtype=torch.bool, device=\"cuda\")\n",
    "context = {\"first\": first}\n",
    "state_in = model.net.initial_state(B) \n",
    "latents, state_out = model.net(input, state_in, {\"first\": first})\n",
    "print(latents[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd37b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0 torch.bool (2, 1, 128)  \n",
      "1 torch.float32 (2, 128, 2048) -79.74006652832031 81.1694564819336\n",
      "2 torch.float32 (2, 128, 2048) -13.02964973449707 20.191967010498047\n",
      "3 torch.bool (2, 1, 128)  \n",
      "4 torch.float32 (2, 128, 2048) -80.62519073486328 112.31578826904297\n",
      "5 torch.float32 (2, 128, 2048) -5.20977783203125 4.960232734680176\n",
      "6 torch.bool (2, 1, 128)  \n",
      "7 torch.float32 (2, 128, 2048) -68.98873138427734 148.8136749267578\n",
      "8 torch.float32 (2, 128, 2048) -4.444644451141357 4.461331367492676\n",
      "9 torch.bool (2, 1, 128)  \n",
      "10 torch.float32 (2, 128, 2048) -804.27001953125 1025.3935546875\n",
      "11 torch.float32 (2, 128, 2048) -10.492900848388672 10.701163291931152\n"
     ]
    }
   ],
   "source": [
    "print(len(state_out))\n",
    "for i, s in enumerate(state_out):\n",
    "    print(i, s.dtype, tuple(s.shape), s.min().item() if s.is_floating_point() else \"\", s.max().item() if s.is_floating_point() else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4bbd4f",
   "metadata": {},
   "source": [
    "Помимо признаков выводится также обновлённый кэш, который подаётся в VPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be30ba",
   "metadata": {},
   "source": [
    "То есть кэш имеет фиксированный размер контекста (T=128), однако на вход мы можем подавать любую последовательность, он посчитает латенты для каждого элемента"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55580e9e",
   "metadata": {},
   "source": [
    "Теперь имплементируем простейший класс для извлечения латентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VPTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, model_name : str, device : str = \"cuda\", eval_mode : bool = True, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        policy = VPTPolicy.from_pretrained(model_name).to(device)\n",
    "        self.device = device\n",
    "        self.net = policy.net.to(device)\n",
    "        if eval_mode:\n",
    "            self.net.eval()\n",
    "     \n",
    "    @torch.no_grad()\n",
    "    def init_state(self, batch_size: int):\n",
    "        st = self.net.initial_state(batch_size)\n",
    "        return [s.to(self.device) for s in st] if st is not None else None\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def forward(self, obs : dict, state_in = None, context = None, pooling_mode = None):\n",
    "        \"\"\"Extract latent features from the VPT model\"\"\"\n",
    "        if \"image\" not in obs:\n",
    "            raise KeyError('Obs must contain \"image\" key')\n",
    "        #x dim: (B, T, H, W, C)\n",
    "        x = obs[\"image\"]\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.as_tensor(x)\n",
    "        if x.dim() != 5:\n",
    "            raise ValueError(f\"image must be in a 5D shape (B, T, H, W, C) but got {x.shape}\")\n",
    "        \n",
    "        B, T = x.shape[:2]\n",
    "        if context is None:\n",
    "            first = torch.zeros((B, T), dtype=torch.bool, device=self.device)\n",
    "            context = {\"first\" : first}\n",
    "        else:\n",
    "            context = dict(context)\n",
    "            context[\"first\"] = context[\"first\"].to(self.device)\n",
    "        if state_in is None:\n",
    "            state_in = self.init_state(B)\n",
    "        else:\n",
    "            state_in = [s.to(self.device) for s in state_in]\n",
    "        \n",
    "        (latents, _), state_out = self.net({\"image\" : x}, state_in, context)\n",
    "        latents = self._pooling(latents, pooling_mode)\n",
    "        return latents, state_out\n",
    "    \n",
    "    def _pooling(self, latents, pooling):\n",
    "      if pooling is None or pooling == 'none':\n",
    "        return latents,  #B, T, D\n",
    "      if pooling == 'last':\n",
    "        return latents[:, -1] #B, D\n",
    "      if pooling == 'mean':\n",
    "        return latents.mean(dim=1) #B, D\n",
    "      return ValueError(f\"pooling can be either none | last | mean but {pooling} was given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff74c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 2048])\n"
     ]
    }
   ],
   "source": [
    "extractor = VPTFeatureExtractor(\"CraftJarvis/MineStudio_VPT.rl_from_early_game_2x\", device=\"cuda\")\n",
    "\n",
    "obs = {\"image\": torch.zeros(2, 16, 128, 128, 3, device=\"cuda\", dtype=torch.uint8)}\n",
    "pi_h, state = extractor(obs, state_in=None, context=None)\n",
    "print(pi_h.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49a4bf",
   "metadata": {},
   "source": [
    "TODO: добавить пулинг с разными режимами: возвращать признаки как есть, возвращать последний токен, возвращать среднее токенов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
